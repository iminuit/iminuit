{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial\n",
    "\n",
    "Welcome to the **iminuit tutorial**. You will learn basic usage of iminuit and how to approach standard fitting problems with iminuit. iminuit is a numerical minimizer and error calculator. You provide it an analytical function, which accepts one or several parameters, and an initial guess of the parameter values. It will then find a local minimum of this function starting from the initial guess. In that regard, iminuit is similar to other minimizers, like those in scipy.optimize.\n",
    "\n",
    "In addition, iminuit has the ability to compute **uncertainty estimates** for model parameters. iminuit was designed to solve statistics problems, where uncertainty estimates are an essential part of the result. Two ways of computing uncertainty estimates are provided with different strengths, the *Hesse* and the *Minos* algorithm.\n",
    "\n",
    "iminuit is the successor of pyminuit. If you used pyminuit before, you will find iminuit very familiar. An important feature of iminuit (and pyminuit) is that it uses introspection to detect the parameter names of your function. This is very convenient, especially when you work interactively in a Jupyter notebook. It also provides special output routines for Jupyter notebooks to pretty print the fit results, as you will see below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iminuit version 1.3.7\n"
     ]
    }
   ],
   "source": [
    "# basic setup of the notebook\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from pprint import pprint # we use this to pretty print some stuff later\n",
    "\n",
    "# everything in iminuit is done through the Minuit object, so we import it\n",
    "from iminuit import Minuit, __version__\n",
    "print(\"iminuit version\", __version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit example\n",
    "\n",
    "For this tutorial, we look at a simple case where line should be fitted to scattered $(x, y)$ data. A line has two parameters $(a, b)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def line(x, a, b):\n",
    "    return a + x * b\n",
    "\n",
    "data_x = np.linspace(0, 1, 10)\n",
    "# precomputed random numbers from a normal distribution\n",
    "offsets = np.array([-0.49783783, -0.33041722, -1.71800806,  1.60229399,  1.36682387,\n",
    "                    -1.15424221, -0.91425267, -0.03395604, -1.27611719, -0.7004073 ])\n",
    "data_y = line(data_x, 1, 2) + 0.1 * offsets # generate some data points with random offsets\n",
    "plt.plot(data_x, data_y, \"o\")\n",
    "plt.xlim(-0.1, 1.1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To recovert the parameters of the line, we fit the line to the scattered data using the method of least-squares. We compute the sum of squared residuals of the $y$ values around the line for a given pair of line parameters $(a, b)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def least_squares(a, b):\n",
    "    yvar = 0.01\n",
    "    return sum((data_y - line(data_x, a, b)) ** 2 / yvar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With iminuit we can find the values of $a$ and $b$ which minimize this sum. Let's do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a = 0.9909664415272811 +/- 0.05877538146463435\n",
      "b = 1.9449447037454664 +/- 0.09908673900884825\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "m = Minuit(least_squares, pedantic=False)\n",
    "m.migrad() # finds minimum of least_squares function\n",
    "m.hesse()  # computes errors \n",
    "\n",
    "# draw data and fitted line\n",
    "plt.plot(data_x, data_y, \"o\")\n",
    "plt.plot(data_x, line(data_x, *m.values.values()))\n",
    "\n",
    "# print parameter values and uncertainty estimates\n",
    "for p in m.parameters:\n",
    "    print(\"{} = {} +/- {}\".format(p, m.values[p], m.errors[p]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, we dive into the details step by step; how the Minuit object is initialized, how to run the algorithms, and how to get the results.\n",
    "\n",
    "iminuit was designed to make it easy to fit functions like `least_squares(a, b)`, where the parameters are individual arguments of the function. There is an alternative function signature that Minuit supports, which is more convenient when you work a lot with numpy. Here, the parameters are passed as a numpy array. The two kinds of function definitions have each pros and cons. We will first dive how to work with functions of the first kind and come back to the second kind later. If you are interested only in the second kind, skip to the section **Alternative: Numpy functions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Minuit\n",
    "\n",
    "To minimize a function, you create an instance of the Minuit class and pass the function to it. This does not start the minimization yet, this will come later. iminuit uses introspection to get the number and names of the function parameters automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hdembinski/Extern/iminuit/py37/lib/python3.7/site-packages/ipykernel_launcher.py:1: InitialParamWarning: Parameter a does not have initial value. Assume 0.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/hdembinski/Extern/iminuit/py37/lib/python3.7/site-packages/ipykernel_launcher.py:1: InitialParamWarning: Parameter a is floating but does not have initial step size. Assume 1.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/hdembinski/Extern/iminuit/py37/lib/python3.7/site-packages/ipykernel_launcher.py:1: InitialParamWarning: Parameter b does not have initial value. Assume 0.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/hdembinski/Extern/iminuit/py37/lib/python3.7/site-packages/ipykernel_launcher.py:1: InitialParamWarning: Parameter b is floating but does not have initial step size. Assume 1.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/hdembinski/Extern/iminuit/py37/lib/python3.7/site-packages/ipykernel_launcher.py:1: InitialParamWarning: errordef is not given. Default to 1.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "m = Minuit(least_squares) # we create an instance of Minuit and pass the function to minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Woah, lots of warnings, we will go through them step-by-step. Note how iminuit refers to your parameters by correct names in the warnings. The filename and line numbers shown in the warnings are bogus in Jupyter notebooks, but refer to the correct file and line when you use iminuit in a script or in the terminal shell.\n",
    "\n",
    "### Initial parameter values\n",
    "\n",
    "iminuit is a local minimizer. It searches for a local minimum by gradient-descent method from a starting point. If your function has several minima, the minimum found will depend on the starting point. Even if it has only one minimum, iminuit will converge to it faster if you start in the proximity of the minimum. If you don't provide a starting value for a parameter, it uses 0. You almost always want to specify a starting point.\n",
    "\n",
    "You can set the starting point using the parameter names as keywords, `<name> = <value>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hdembinski/Extern/iminuit/py37/lib/python3.7/site-packages/ipykernel_launcher.py:1: InitialParamWarning: Parameter a is floating but does not have initial step size. Assume 1.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/hdembinski/Extern/iminuit/py37/lib/python3.7/site-packages/ipykernel_launcher.py:1: InitialParamWarning: Parameter b is floating but does not have initial step size. Assume 1.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/hdembinski/Extern/iminuit/py37/lib/python3.7/site-packages/ipykernel_launcher.py:1: InitialParamWarning: errordef is not given. Default to 1.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "m = Minuit(least_squares, a=5, b=5) # pass starting values for a and b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial step sizes\n",
    "\n",
    "iminuit further wants initial step sizes. iminuit uses a gradient-descent method to find the minimum and the gradient is computed numerically using finite differences. The initial step size is used to compute the first gradient. If you don't provide a value, it uses 1. A good step size is small compared to the curvature of the function, but large compared to numerical resolution.\n",
    "\n",
    "You can set initital step sizes with keywords, `error_<name> = <step size>`. If you don't know what to pick, don't worry too much. Usually, the choice is not important. In the worst case, iminuit will use a few more function evaluations to find the minimum. A good guess is a fraction of the initial fit parameter value, e.g. 10 % (be careful when applying this rule-of-thumb when your the initial parameter value is zero).\n",
    "\n",
    "Using an appropriate step size is important when you have you a parameter which has physical bounds. Varying the initial parameter value by the step size may not create a situation where the parameter goes outside of its bounds. For example, a parameter $x$ with $x > 0$ and initital value $0.1$ may not have a step size of $0.2$. If you follow the recommendation of using 10 % of the initial value, you never run into this problem.\n",
    "\n",
    "In our example, we use an initital step size of $\\Delta a = \\Delta b = 0.1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hdembinski/Extern/iminuit/py37/lib/python3.7/site-packages/ipykernel_launcher.py:1: InitialParamWarning: errordef is not given. Default to 1.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "m = Minuit(least_squares, a=5, b=5, error_a=0.1, error_b=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error definition\n",
    "\n",
    "Only one warning left. Minuit asks you to explicitly provide a value for the error definition with the `errordef` keyword. This is needed to get correct uncertainty estimates for your parameters. In statistical problems, there are two kinds of functions to minimize, the *negative log-likelihood* and the *least-squares* function. Each has a corresponding value for `errordef`:\n",
    " - `0.5` or the constant `Minuit.LIKELIHOOD` for negative log-likelihood functions \n",
    " - `1` or the constant `Minuit.LEAST_SQUARES` for least-squares functions \n",
    "\n",
    "The origin of these numbers is not complicated, but cannot be explained briefly, so if you are curious, we suggest a statistics book for physicists, e.g. G. Cowan, \"Statistical Data Analysis\", Oxford Science Publications.\n",
    "\n",
    "If you don't care about uncertainty estimates, just use the  `errordef` default and pass `pedantic=False` to turn off all warnings.\n",
    "\n",
    "For our example, we need to pass `errordef=1` or `errordef=Minuit.LEAST_SQUARES`, because we are minimizing a least-squares function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'iminuit._libiminuit.Minuit' has no attribute 'LEAST_SQUARES'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-d8fd8598eb1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMinuit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleast_squares\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_a\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrordef\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMinuit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLEAST_SQUARES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'iminuit._libiminuit.Minuit' has no attribute 'LEAST_SQUARES'"
     ]
    }
   ],
   "source": [
    "m = Minuit(least_squares, a=5, b=5, error_a=0.1, error_b=0.1, errordef=Minuit.LEAST_SQUARES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now iminuit is happy, all optional information is provided.\n",
    "\n",
    "If you want to quickly minimize a function and you know that the defaults are ok, you can also explicitly silence all warnings, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Minuit(least_squares, pedantic=False)  # silence warnings, use default values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can always check the current parameter settings with the method `Minuit.get_param_states()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, this produces a nice table. The table will be updated once you run the actual minimization. To look at the initital conditions later, use `Minuit.get_initial_param_states()`. We will come back to the meaning of *Hesse Error* and *Minos Error*, when we discuss the actual minimization.\n",
    "\n",
    "Before we do that, let's see what else we can specify in the initialization.\n",
    "\n",
    "### Parameters with limits\n",
    "\n",
    "iminuit allows you to set parameter limits. Often a parameter is limited mathematically or physically to a certain range. For example, if your function contains `sqrt(x)`, then $x$ must be non-negative, $x \\ge 0$. You can set upper-, lower-, or two-sided limits for each parameter individually with keywords `limit_<name>`:\n",
    "\n",
    "- lower limit: use `limit_<name> = (<value>, None)` or `(<value>, float(\"infinity\"))`\n",
    "- upper limit: use `limit_<name> = (None, <value>)` or `(-float(\"infinity\"), <value>)`\n",
    "- two-sided limit: use `limit_<name> = (<min_value>, <max_value>)`\n",
    "\n",
    "To impose the limits $a \\ge 0$ and $0 \\le b \\le 10$ in our example, you do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Minuit(least_squares, a=5, b=5,\n",
    "           error_a=0.1, error_b=0.1,\n",
    "           limit_a=(0, None), limit_b=(0, 10),\n",
    "           errordef=1)\n",
    "m.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Initially) Fixed parameters\n",
    "\n",
    "Sometimes you have a parameter which you want to set to a fixed value temporarily. Perhaps you have a guess for its value, and you want to see how the other parameters adapt when this parameter is fixed to that value.\n",
    "\n",
    "Or you have a complex function with many parameters that do not all affect the function at the same scale. Then you can manually help the minimizer to find the minimum faster by first fixing the less important parameters to initial guesses and fit only the important parameters. Once the minimum is found under these conditions, you can release the fixed parameters and optimize all parameters together. Minuit remembers the last state of the minimization and starts from there. The minimization time roughly scales with the square of the number of parameters. Iterated minimization over subspaces of the parameters can reduce that time.\n",
    "\n",
    "To fix an individual parameter, you use the keyword `fix_<name> = True`. In our example, we fix $x$, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Minuit(least_squares, a=5, b=5, fix_a=True,\n",
    "           error_a=0.1, error_b=0.1,\n",
    "           errordef=1)\n",
    "m.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# migrad will not vary a, only b\n",
    "m.migrad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we release a and fix b and minimize again\n",
    "m.fixed[\"a\"] = False\n",
    "m.fixed[\"b\"] = True\n",
    "m.migrad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convergence is slow in this case, let's release both parameters and minimize again\n",
    "for key in m.fixed:\n",
    "    m.fixed[key] = False\n",
    "m.migrad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible and sometimes useful to change the values of some fixed parameters by hand and fit the others, or to restart the fit from another starting point. This can also be done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.fixed[\"a\"] = True\n",
    "m.values[\"a\"] = 0.5\n",
    "m.migrad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.values[\"a\"] = 1\n",
    "m.migrad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.values[\"a\"] = 1.5\n",
    "m.migrad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Override paramater name detection\n",
    "\n",
    "iminuit tries hard to find out the parameter names and is pretty good at it. For example, if you pass a functor instead of a function, it will use the arguments of the `__call__` method, automatically skipping `self`.\n",
    "\n",
    "To see which parameter names iminuit finds for your function, use the `describe` function, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from iminuit import describe\n",
    "\n",
    "def foo(x, y, z): pass\n",
    "assert describe(foo) == ['x', 'y', 'z']\n",
    "\n",
    "class Foo:\n",
    "    def __call__(self, a, b):\n",
    "        pass\n",
    "\n",
    "assert describe(Foo()) == ['a', 'b']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works very well, but for some functions, the parameter names cannot be determined. An obvious case are functions which accept a variable number of arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar(*args):  # function with variable number of arguments\n",
    "    return np.sum((np.array(args) - 1) ** 2)\n",
    "\n",
    "try:\n",
    "    describe(bar)  # this will raise a TypeError\n",
    "except TypeError as e:\n",
    "    pprint(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `TypeError` is raised, because `describe` cannot detect the number and names of the parameters in this case. If you work with functions that accept a variable number of arguments a lot, we recommend to use vectorized functions, as explained in the next section.\n",
    "\n",
    "When iminuit cannot detect the arguments, but you know how many arguments there are, or if you simply want to override the names found by iminuit, you can do that with the keyword `forced_parameters`, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Minuit(bar, forced_parameters=('a', 'b'), a=1, b=2, pedantic=False)\n",
    "m.migrad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative: Vectorized functions\n",
    "\n",
    "You can also use iminuit with functions that accept numpy arrays. This has pros and cons.\n",
    "\n",
    "**Pros**\n",
    "- Easy to change number of fitted parameters\n",
    "- Sometimes simpler function body that's easier to read\n",
    "- Technically more efficient, although this is probably not noticable unless you have >100 parameters\n",
    "\n",
    "**Cons**\n",
    "- iminuit cannot figure out names for each parameter\n",
    "\n",
    "Let's take the original `least_squares` function and write a vectorized version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def least_squares_np(par):  # par is a numpy array here \n",
    "    mu = np.polyval(par, data_x)  # for par = (a, b) this is a line\n",
    "    yvar = 0.01\n",
    "    return np.sum((data_y - mu) ** 2 / yvar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`least_square(a, b)` and `least_squares_np(par)` are alternative implementations of the same mathematical function, if the latter is called with two arguments. In contrast to `least_squares`, `least_squares_np` can also be called with fewer or more arguments, using a polynomial of the corresponding order predict the behavior of the data. This will come in handy. \n",
    "\n",
    "To pass a numpy function, create a Minuit object with the method `Minuit.from_array_func`. Using the function `least_squares_np(par)` described above as an example, the call looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Minuit.from_array_func(least_squares_np, (5, 5), error=(0.1, 0.1), errordef=1)\n",
    "m.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first argument after the function is the starting point, which you provide as a sequence here. iminuit uses the length of this sequence to detect how many parameters your function has. As before you can use the keywords `error`, `limit`, and `fix`, to set initial step sizes, parameter limits, and fix parameters. These must be sequences with the same length as the starting point. For `error` and `limit`, it is also allowed to give a single step size or a single limit, which is then used for all parameters.\n",
    "\n",
    "By default, the parameters are named automatically `x0` to `xN`. You can override this with the keyword `name`, passing a sequence of parameter names, like so: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Minuit.from_array_func(least_squares_np, (5, 5), error=(0.1, 0.1), fix=(True, False),\n",
    "                           limit=((0, None), (0, 10)),\n",
    "                           name = (\"a\", \"b\"), errordef=1)\n",
    "m.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since `least_squares_np(par)` works for numpy arrays of any length, you can easily change the number of fitted parameters by changing the length of the starting array, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Minuit.from_array_func(least_squares_np, (5, 5, 5, 5), error=0.1, errordef=1)\n",
    "m.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is useful when you fit a polynomial to parametrize some data and you want to try different orders of the polynomial. If the order is too small, the polynomial will not follow the data. If it is too large, you will overfit the data and polynomial will pick up random fluctuations and not the underlying trend. You can figure out the right order by experimenting or using an algorithm like cross-validation.\n",
    "\n",
    "If you are very familiar with numpy and scipy, you may find the `minimize` function useful. It exactly mimics the function interface of `scipy.optimize.minimize`, but uses `Minuit` for the actual minimization. You need to have `scipy` installed to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from iminuit import minimize  # has same interface as scipy.optimize.minimize\n",
    "minimize(least_squares_np, (5, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimize the function\n",
    "\n",
    "To run the actual minimization, you call the `Minuit.migrad()` method. Migrad performs Variable-Metric Minimization. It combines a steepest-descends algorithm along with line search strategy. Migrad is very popular in high energy physics field because of its robustness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m = Minuit(least_squares, a=5, b=5, error_a=0.1, error_b=0.1, errordef=1)\n",
    "m.migrad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method returns two dict-like objects, which contain information about the function minimum and the parameter state. In a notebook, these objects are nicely rendered as tables. This is good for a quick check:\n",
    "\n",
    "- All blocks should be green.\n",
    "- Red means something bad. \n",
    "- Yellow is a caution (fit is good but you ran over call limit)\n",
    "\n",
    "Let's look at the actual object. The first is the function minimum `fmin`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(m.fmin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important one here is `is_valid`. If this is false, the fit did not converge and the result is useless. If that happens, there can be many reasons.\n",
    "\n",
    "- The fit function is not analytical everywhere in the parameter space or does not have a local minimum (the minimum may be at infinity, the extremum may be a saddle point or maximum). Indicators for this are `is_above_max_edm=True`, `hesse_failed=True`, `has_posdef_covar=False`, or `has_made_posdef_covar=True`.\n",
    "- Migrad reached the call limit before the convergence so that `has_reached_call_limit=True`. The used number of function calls is `nfcn`, and the call limit can be changed with the keyword argument `ncall` in the method  `Minuit.migrad`. Note that `nfcn` can be slightly larger than `ncall`, because Migrad internally only checks this condition after a full iteration step, in which several function calls can happen.\n",
    "\n",
    "Migrad detects converge by a small `edm` value, the *estimated distance to minimum*. This is the difference between the current minimum value of the minimized function and the next prediction based on a local quadratic approximation of the function (something that Migrad computes as part of its algorithm). If the fit did not converge, `is_above_max_edm` is true.\n",
    "\n",
    "If you are interested in parameter uncertainties, you should make sure that:\n",
    "\n",
    "- `has_covariance`, `has_accurate_covar`, and `has_posdef_covar` are true.\n",
    "- `has_made_posdef_covar` and `hesse_failed` are false.\n",
    "\n",
    "**Beware**: Migrad sometimes reports `is_valid=True` even when the result is wrong. There are some known and perhaps some hidden bugs in the Migrad code which cause this. When you find such a case, please report it, so that we can forward it to the maintainers of C++ Minuit. We advice to carefully check the fit result in any case for consistency, for example, by plotting the fitted function on top of the data to see that they match.\n",
    "\n",
    "The second object of interest after the fit is the parameter list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pprint(m.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a list of dict-like objects which contain information about the fitted parameters. Important fields are:\n",
    "- `index`: parameter index.\n",
    "- `name`: parameter name.\n",
    "- `value`: value of the parameter at the minimum.\n",
    "- `error`: uncertainty estimate for the parameter value.\n",
    "\n",
    "Whether the uncertainty estimate is accurate depends on the correct mathematical modeling of your fitting problem and using the right `errordef` value for Minuit (which one to use was already explained earlier).\n",
    "\n",
    "What do we mean by correct mathematical modelling? If you look into the function `least_squares(a, b)`, you see that each squared residuals is divided by the expected stochastic variance of the residual. This is necessary to get accurate uncertainty estimates for the parameters.\n",
    "\n",
    "Often the expected variance of the residual is not exactly known, but it usually can be approximated. If the function to minimize is a least-squares function, there is a simple test to check whether the residual variances are accurate. You look at the function value at the minimum, here given by `fmin.fval`, and divide it by the difference of the number of residuals and the number of fitted parameters. This is so-called reduced chi2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.fval / (len(data_y) - 2)  # reduced chi2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This value should be around 1. The more residuals you have, the closer. If the value is much larger than 1, then you either underestimate the variance of the residuals or your model does not describe the data. If the value is much smaller than 1, then you overestimate the variance of the residuals.\n",
    "\n",
    "##  Parameter uncertainties, covariances, and confidence intervals\n",
    "\n",
    "You saw how to get the uncertainty of each individual parameter, but parameters are usually correlated. This is essential additional information if you want to work with parameter uncertainties seriously. We will discuss next how you access that.\n",
    "\n",
    "Minuit offers two ways to compute the parameter uncertainties, Hesse and Minos. Both have pros and cons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hesse for covariance and correlation matrices\n",
    "\n",
    "The Hesse algorithm numerically computes the matrix of second derivatives at the function minimum (called the Hesse matrix) and inverts it. The Hesse matrix is symmetric by construction. In the limit of infinite data samples to fit, the result of this computation converges to the true covariance matrix of the parameters. It often is already a good approximation even for finite statistic. These errors obtained from this method are sometimes called *parabolic errors*, because the Hesse matrix method is exact if the function is a hyperparabola (third and higher-order derivatives are all zero).\n",
    "\n",
    "Pros:\n",
    "- (Comparably) fast computation.\n",
    "- Provides covariance matrix for error propagation.\n",
    "\n",
    "Cons:\n",
    "- Wrong if function does not look like a hyperparabola around the minimum\n",
    "\n",
    "The Migrad algorithm computes an approximation of the Hesse matrix automatically during minimization. When the default strategy is used, Minuit does a check whether this approximation is sufficiently accurate and if not, it computes the Hesse matrix automatically.\n",
    "\n",
    "All this happens inside C++ Minuit and is a bit intransparent, so we recommend to call `Minuit.hesse` explicitly after the minimization if exact errors are important, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's mess up the current errors a bit so that hesse has something to do\n",
    "m.errors[\"a\"] = 0.16\n",
    "m.errors[\"b\"] = 0.2\n",
    "m.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.hesse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The call returns the updated parameter list, which is again rendered as a table.\n",
    "\n",
    "#### Correlation and Covariance Matrix\n",
    "\n",
    "To see the correlation matrix of the parameters, you do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "m.matrix(correlation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The paramaters $a$ and $b$ are stronly anti-correlated, which is highlighed by the blue color of the off-diagonal elements.\n",
    "\n",
    "Correlation is not necessarily a bad thing, but if you have freedom in redefining the parameters of the fit function, it is good to chose parameters which are not strongly correlated.\n",
    "\n",
    "Minuit cannot accurately minimise the function if two parameters are (almost) perfectly (anti-)correlated. It also means that one of two parameters is superfluous, it doesn't add new information. You should rethink the fit function in this case and try to remove one of the parameters from the fit.\n",
    "\n",
    "You can also look at the covariance matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "m.matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "source": [
    "To see the matrices as Python objects, use `pprint`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(m.matrix(correlation=True))  # correlation matrix as before\n",
    "pprint(m.matrix())  # covariance matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want the matrix as a numpy array (useful for error propagation), use the `np_` methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(m.np_matrix())  # m.np_matrix(correlation=True) also works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minos for non-parabolic minima\n",
    "\n",
    "Minuits other algorithm to compute uncertainties is Minos. It implements the so-called profile likelihood method, where the neighborhood around the function minimum is scanned until the contour is found where the function increase by the value of `errordef`. The contour defines a confidence region that approximately covers the true parameter point with a certain confidence. The contour is exact in the limit of infinitely large data samples and approximate for the finite case (although the approximation is usually very good). Please consult a textbook about statistics about the mathematical details.\n",
    "\n",
    "Minos provides a better answer than Hesse, if the neighborhood around the minimum is very different from a hyperparabola (e.g. banana shaped), but it takes much much longer to compute.\n",
    "\n",
    "Pros:\n",
    "- Good for functions which are not very close to a hyper-parabola around the minimum\n",
    "- Produces pretty confidence regions for scientific plots\n",
    "\n",
    "Cons:\n",
    "- Takes really long time\n",
    "- Result is difficult to error-propagate, since it cannot be described by a covariance matrix\n",
    "\n",
    "Minos is not automatically called during minimization, it needs to be called explicitly afterwards, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.minos()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By now you are probably used to see green colors, which indicate that Minos ran successful. Be careful when these are red instead. The fields in the table mean the following:\n",
    "- At Limit: Whether Minos hit a parameter limit before the finishing the contour.\n",
    "- Max FCN: Whether Minos reached the maximum number of allowed calls before finishing the contour.\n",
    "- New Min: Whether Minos discovered a deeper local minimum in the neighborhood of the current one.\n",
    "\n",
    "The errors computed by Minos are now also shown in the parameter list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the absolute values of the Minos errors are very close to the Hesse Error, the function is well approximated by a hyperparabola around the minimum. You can use this as a check instead of explicitly plotting the function around the minimum (for which we provide tools, see below)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick access to fit results\n",
    "\n",
    "If working with the dicts returned by `Minuit.migrad` and `Minuit.minos` is not your thing, you can also get the fit results with properties and methods. There are many, please check the reference of `Minuit`. Here are the most important ones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(m.values)  # dict-like view of the parameter values\n",
    "# access values by name or index\n",
    "pprint(\"by name\")\n",
    "pprint(m.values[\"a\"])\n",
    "pprint(\"by index\")\n",
    "pprint(m.values[0])\n",
    "\n",
    "# you can also iterate over the view like you would over a dict\n",
    "for key, value in m.values.items():\n",
    "    pprint((key, value))\n",
    "\n",
    "pprint(\"Hesse errors\")\n",
    "pprint(m.errors)  # dict-like view of symmetric uncertainties\n",
    "# you can access errors in the same ways as for m.values\n",
    "\n",
    "pprint(\"Minos errors\")\n",
    "pprint(m.merrors)  # asymmetric uncertainties\n",
    "pprint(\"Hesse covariance\")\n",
    "pprint(m.covariance)  # the covariance matrix computed by Hesse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that you can play around with iminuit by assigning new values to `m.values` and `m.errors`. The values will be used as a starting point when you call `m.migrad()` again.\n",
    "\n",
    "There are also corresponding methods that return numpy arrays, convenient if you use numpy functions. Note that these methods create copies. The numpy arrays are not views like the attributes. Changing the values of the numpy array does not change the state that `Minuit` sees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# note these are methods and not a properties\n",
    "pprint(m.np_values())\n",
    "pprint(m.np_errors())\n",
    "pprint(m.np_merrors())\n",
    "pprint(m.np_covariance())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The layout for most of these is straight-forward, but for `Minuit.np_merrors()` it is different. The layout returned by `Minuit.np_merrors()` follows the convention `[abs(delta_down), delta_up]` that is used by `matplotlib.pyplot.errorbar`. This makes passing Hesse and Minos errors to matplotlib straight-forward. You can see an example here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = m.np_values()\n",
    "ve = m.np_errors()\n",
    "vm = m.np_merrors()\n",
    "# show hesse errors\n",
    "plt.errorbar((0, 1), v, ve, fmt=\"ob\");\n",
    "# show minos errors\n",
    "plt.errorbar((0.01, 1.01), v, vm, fmt=\"or\"); # add a little offset so that the error bars don't overlap\n",
    "plt.xlabel(\"parameter index\")\n",
    "plt.xticks((0, 1))\n",
    "plt.xlim(-0.1, 1.1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting\n",
    "\n",
    "iminuit comes with buildin methods to draw the confidence regions around the minimum, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.draw_mncontour('a','b', nsigma=4);  # nsigma=4 says: draw four contours from sigma=1 to 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get individual minos contours for plotting them yourself\n",
    "param_a, param_b, ctr_xy = m.mncontour('a','b', sigma=2, numpoints=10)\n",
    "pprint(ctr_xy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you need to inspect the cost function around the minimum because MINUIT warns you about some issues, you can quickly scan cost function around the current parameter values, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1D value Scan\n",
    "a, fa = m.profile('a')\n",
    "plt.plot(a, fa);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# or use this function for a quick look\n",
    "m.draw_profile('a');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternativel, you can use `mnprofile` to do a full profile likelihood scan. This mimics what MINOS does to compute confidence intervals. If you have trouble with MINOS, running this may help to inspect the issue.\n",
    "\n",
    "This is computationally expensive, since the scan runs MIGRAD for each point on the profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.draw_mnprofile('a');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, you can also look at the 2D contours of the cost function around the minimum. Note that these are just contours of the fit function, not confidence regions. The latter you can only get from `mncontour`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y,z = m.contour('a', 'b', subtract_min=True)\n",
    "cs = plt.contour(x,y,z, (1, 2, 3, 4)) # these are not sigmas, just the contour values\n",
    "plt.clabel(cs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or use this function for a quick look\n",
    "m.draw_contour('a', 'b', show_sigma=True);"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
